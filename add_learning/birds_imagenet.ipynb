{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "birds_imagenet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Nsg9cNn-ptXb"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/oleges1/practise/blob/master/add_learning/birds_imagenet.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ErQ17cC4qF_l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare gdrive"
      ]
    },
    {
      "metadata": {
        "id": "HuaZLZksZtMn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2416
        },
        "outputId": "3b3f9dd2-8b00-42b3-b493-953a75eb2771"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 18408 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128ubuntu5) ...\n",
            "Selecting previously unselected package libapparmor1:amd64.\n",
            "Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n",
            "Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Selecting previously unselected package libdbus-1-3:amd64.\n",
            "Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dbus.\n",
            "Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking dbus (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dirmngr.\n",
            "Preparing to unpack .../04-dirmngr_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Selecting previously unselected package distro-info-data.\n",
            "Preparing to unpack .../05-distro-info-data_0.36ubuntu0.2_all.deb ...\n",
            "Unpacking distro-info-data (0.36ubuntu0.2) ...\n",
            "Selecting previously unselected package libkmod2:amd64.\n",
            "Preparing to unpack .../06-libkmod2_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Selecting previously unselected package kmod.\n",
            "Preparing to unpack .../07-kmod_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking kmod (24-1ubuntu2) ...\n",
            "Selecting previously unselected package lsb-release.\n",
            "Preparing to unpack .../08-lsb-release_9.20160110ubuntu5_all.deb ...\n",
            "Unpacking lsb-release (9.20160110ubuntu5) ...\n",
            "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
            "Preparing to unpack .../09-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n",
            "Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
            "Preparing to unpack .../10-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package iso-codes.\n",
            "Preparing to unpack .../11-iso-codes_3.75-1_all.deb ...\n",
            "Unpacking iso-codes (3.75-1) ...\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "Preparing to unpack .../12-libdbus-glib-1-2_0.108-2_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Selecting previously unselected package python-apt-common.\n",
            "Preparing to unpack .../13-python-apt-common_1.4.0~beta3build2_all.deb ...\n",
            "Unpacking python-apt-common (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-apt.\n",
            "Preparing to unpack .../14-python3-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python3-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-dbus.\n",
            "Preparing to unpack .../15-python3-dbus_1.2.4-1build3_amd64.deb ...\n",
            "Unpacking python3-dbus (1.2.4-1build3) ...\n",
            "Selecting previously unselected package python3-gi.\n",
            "Preparing to unpack .../16-python3-gi_3.24.1-2build1_amd64.deb ...\n",
            "Unpacking python3-gi (3.24.1-2build1) ...\n",
            "Selecting previously unselected package module-init-tools.\n",
            "Preparing to unpack .../17-module-init-tools_24-1ubuntu2_all.deb ...\n",
            "Unpacking module-init-tools (24-1ubuntu2) ...\n",
            "Selecting previously unselected package python-apt.\n",
            "Preparing to unpack .../18-python-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python-pycurl.\n",
            "Preparing to unpack .../19-python-pycurl_7.43.0-2build2_amd64.deb ...\n",
            "Unpacking python-pycurl (7.43.0-2build2) ...\n",
            "Selecting previously unselected package python-software-properties.\n",
            "Preparing to unpack .../20-python-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package python3-software-properties.\n",
            "Preparing to unpack .../21-python3-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python3-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package software-properties-common.\n",
            "Preparing to unpack .../22-software-properties-common_0.96.24.17_all.deb ...\n",
            "Unpacking software-properties-common (0.96.24.17) ...\n",
            "Selecting previously unselected package unattended-upgrades.\n",
            "Preparing to unpack .../23-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n",
            "Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n",
            "Setting up python-apt-common (1.4.0~beta3build2) ...\n",
            "Setting up python3-apt (1.4.0~beta3build2) ...\n",
            "Setting up iso-codes (3.75-1) ...\n",
            "Setting up distro-info-data (0.36ubuntu0.2) ...\n",
            "Setting up python-pycurl (7.43.0-2build2) ...\n",
            "Setting up lsb-release (9.20160110ubuntu5) ...\n",
            "Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Setting up libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Setting up unattended-upgrades (0.98ubuntu1.1) ...\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Setting up cron (3.0pl1-128ubuntu5) ...\n",
            "Adding group `crontab' (GID 102) ...\n",
            "Done.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Setting up kmod (24-1ubuntu2) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Setting up python3-gi (3.24.1-2build1) ...\n",
            "Setting up module-init-tools (24-1ubuntu2) ...\n",
            "Setting up python3-software-properties (0.96.24.17) ...\n",
            "Setting up dbus (1.10.22-1ubuntu1) ...\n",
            "Setting up python-apt (1.4.0~beta3build2) ...\n",
            "Setting up python3-dbus (1.2.4-1build3) ...\n",
            "Setting up python-software-properties (0.96.24.17) ...\n",
            "Setting up software-properties-common (0.96.24.17) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Processing triggers for dbus (1.10.22-1ubuntu1) ...\n",
            "gpg: keybox '/tmp/tmp61grld93/pubring.gpg' created\n",
            "gpg: /tmp/tmp61grld93/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 19816 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6W1g42ulaGQe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7045cf06-cc89-4a8a-a505-3cd041a5d6ac"
      },
      "cell_type": "code",
      "source": [
        "!ls drive/birds/00_input/train/ -a"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".  ..  gt.csv  images  images_reshaped\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Nsg9cNn-ptXb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare directory for flow_from_directory method in keras"
      ]
    },
    {
      "metadata": {
        "id": "PS4RCpAGjBeJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_to_imgs = 'drive/birds/00_input/train/images'\n",
        "path_to_csv =  'drive/birds/00_input/train/gt.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qisbef6CprQ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "10cdef09-c00f-4730-9c3a-597bbfeb9823"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "# source is the current directory\n",
        "# Open dataset file\n",
        "dataset = pd.read_csv(path_to_csv)\n",
        "file_names = list(dataset['filename'].values)\n",
        "img_labels = list(dataset['class_id'].values)\n",
        "\n",
        "folders_to_be_created = np.unique(list(dataset['class_id'].values))\n",
        "\n",
        "source = os.getcwd()\n",
        "\n",
        "for new_path in folders_to_be_created:\n",
        "    if not os.path.exists(path_to_imgs + '/' +  str(new_path)):\n",
        "        os.makedirs(path_to_imgs + '/' +  str(new_path))\n",
        "\n",
        "folders = folders_to_be_created.copy()\n",
        "\n",
        "for f in range(len(file_names)):\n",
        "\n",
        "  current_img = file_names[f]\n",
        "  current_label = img_labels[f]\n",
        "\n",
        "  shutil.move(path_to_imgs + '/' + str(current_img), path_to_imgs + '/' + str(current_label))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-95f8889e5cde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnew_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolders_to_be_created\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_imgs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_imgs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "0QGaF1hMF85c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp -r drive/birds/00_input/train/images drive/birds/00_input/train/images_validation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iyls1Qd0INR6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for new_path in folders_to_be_created:\n",
        "    if not os.path.exists('drive/birds/00_input/train/validation' + '/' +  str(new_path)):\n",
        "        os.makedirs('drive/birds/00_input/train/validation' + '/' +  str(new_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Q18QXbz8cKd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5d22bdf-92e2-45f0-f54f-281526b0b515"
      },
      "cell_type": "code",
      "source": [
        "!ls drive/birds/00_input/train/images_validation/28 -l | wc"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     49     437    2540\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y_A5b9iIp3QY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Main  model"
      ]
    },
    {
      "metadata": {
        "id": "qzb-1c2x_oAh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Try diffrent model and test them using validation"
      ]
    },
    {
      "metadata": {
        "id": "V4CuMhnasf3_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = 'drive/birds/00_input/train/images'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g5tMiPXUufMX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_to_gt = 'drive/birds/00_input/train/gt.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FdWXTy-SwdZ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "676489b3-9881-43b8-d547-3dc9f3276432"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install tqdm"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.25.0)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MvCwu9VBux7L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ed2be59-1608-4990-85c7-0d423d1f8e46"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from random import randint\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Activation, GlobalMaxPooling2D, Dropout, Conv2D, MaxPooling2D, Flatten, Reshape, BatchNormalization\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.callbacks import LambdaCallback, ProgbarLogger\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "\n",
        "#from run_tests import read_csv, save_csv\n",
        "\n",
        "from skimage.transform import resize\n",
        "from random import randint"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "9PUmEksFtwpJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_csv(filename):\n",
        "    res = {}\n",
        "    with open(filename) as fhandle:\n",
        "        next(fhandle)\n",
        "        for line in fhandle:\n",
        "            filename, class_id = line.rstrip('\\n').split(',')\n",
        "            res[filename] = int(class_id)\n",
        "    return res\n",
        "\n",
        "def rotare(img, times):\n",
        "    if times == 0:\n",
        "      return img\n",
        "    if times == 1:\n",
        "      return np.rot90(img)\n",
        "    if times == 2:\n",
        "      return np.rot90(np.rot90(img))\n",
        "    if times == 3:\n",
        "      return np.rot90(np.rot90(np.rot90(img)))\n",
        "\n",
        "\n",
        "def generator(train_img_dir, dataset, batch_size = 1, fast_run = True):\n",
        "    x_batch = np.zeros((batch_size, 299, 299, 3), dtype = np.float32)\n",
        "    y_batch = np.zeros((batch_size, 50))\n",
        "    i = 0\n",
        "    full_indx = np.arange(len(dataset))\n",
        "    np.random.shuffle(full_indx)\n",
        "    \n",
        "    begin_batch = 0\n",
        "    while True:\n",
        "        if fast_run:\n",
        "          filename_idxs = np.random.choice(len(dataset), batch_size)\n",
        "        else:\n",
        "          if begin_batch + batch_size < len(dataset):\n",
        "              filename_idxs = full_indx[begin_batch : begin_batch + batch_size]\n",
        "              begin_batch += batch_size\n",
        "          else:\n",
        "              filename_idxs = full_indx[begin_batch : len(dataset)]\n",
        "              begin_batch = (begin_batch + batch_size) % len(dataset)\n",
        "              filename_idxs += full_indx[0 : begin_batch]\n",
        "\n",
        "        filenames = [list(dataset.keys())[filename_idx] for filename_idx in filename_idxs]\n",
        "        for i in range(batch_size):\n",
        "            image = np.array(load_img(train_img_dir + '/' +  filenames[i], target_size = (299, 299)), dtype = np.float32)\n",
        "            if not fast_run:\n",
        "                seed = randint(0, 3)\n",
        "                image = rotare(image, seed)\n",
        "            image -= np.mean(image, keepdims=True)\n",
        "            image /= (np.std(image, keepdims=True) + 0.00001)\n",
        "            x_batch[i] = image\n",
        "            y_batch[i][dataset[filenames[i]]] = 1\n",
        "        yield x_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "30eyT6al1hRV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class data_storage():\n",
        "  def __init__(self, path, path_to_gt, path_to_datas = ['drive/birds/x.npy', 'drive/birds/y.npy']):\n",
        "      self.path = path\n",
        "      self.path_to_gt = path_to_gt\n",
        "      \n",
        "      self.dataset = {}\n",
        "      with open(path_to_gt) as fhandle:\n",
        "          next(fhandle)\n",
        "          for line in fhandle:\n",
        "              filename, class_id = line.rstrip('\\n').split(',')\n",
        "              self.dataset[filename] = int(class_id)\n",
        "      \n",
        "      if path_to_datas != None:\n",
        "          self.x = np.load(path_to_datas[0])\n",
        "          self.y = np.load(path_to_datas[1])\n",
        "          return\n",
        "\n",
        "      self.x = np.zeros((len(self.dataset), 299, 299, 3), dtype = np.float32)\n",
        "      self.y = np.zeros((len(self.dataset), 50))\n",
        "      filenames = [list(self.dataset.keys())[filename_idx] for filename_idx in range(len(self.dataset))]\n",
        "      for i in tqdm(range(len(self.dataset))):\n",
        "          image = np.array(load_img(path + '/' +  filenames[i], target_size = (299, 299)), dtype = np.float32)\n",
        "          #image -= np.mean(image, keepdims=True)\n",
        "          #image /= (np.std(image, keepdims=True) + 0.00001)\n",
        "          self.x[i] = image\n",
        "          self.y[i][self.dataset[filenames[i]]] = 1\n",
        "          \n",
        "   \n",
        "  # better to use keras flow\n",
        "  def generator(self, fast_run = False):\n",
        "      x_batch = np.zeros((batch_size, 299, 299, 3), dtype = np.float32)\n",
        "      y_batch = np.zeros((batch_size, 50))\n",
        "      full_indx = np.arange(len(dataset))\n",
        "      np.random.shuffle(full_indx)\n",
        "      begin_batch = 0\n",
        "      while True:\n",
        "        if fast_run:\n",
        "            filename_idxs = np.random.choice(len(dataset), batch_size)\n",
        "        else:\n",
        "            if begin_batch + batch_size < len(dataset):\n",
        "                filename_idxs = full_indx[begin_batch : begin_batch + batch_size]\n",
        "                begin_batch += batch_size\n",
        "            else:\n",
        "                filename_idxs = full_indx[begin_batch : len(dataset)]\n",
        "                begin_batch = (begin_batch + batch_size) % len(dataset)\n",
        "                filename_idxs += full_indx[0 : begin_batch]\n",
        "        filenames = [list(dataset.keys())[filename_idx] for filename_idx in filename_idxs]\n",
        "        \n",
        "        for i in range(batch_size):\n",
        "            image = self.x[filename_idxs[i]]\n",
        "            seed = randint(0, 3)\n",
        "            image = rotare(image, seed)\n",
        "            \n",
        "            x_batch[i] = image\n",
        "            y_batch[i][dataset[filenames[i]]] = 1\n",
        "        yield x_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EtD8dYOBwiwK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "full_data = data_storage(path, path_to_gt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oOOkMSzaNc-O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "full_data.x, full_data.y = shuffle(full_data.x, full_data.y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wUQLomuprv2a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d6ece611-3d99-48a7-b908-b25c14eb326a"
      },
      "cell_type": "code",
      "source": [
        "!free -h"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\r\n",
            "Mem:            12G        5.6G        151M        249M        7.0G        9.1G\r\n",
            "Swap:            0B          0B          0B\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ojhxYxjpgqKO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# base_model = InceptionV3(weights='imagenet', include_top = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5SBXNyE1gtwh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# base_model.predict(full_data.x[0].reshape([1, 299, 299, 3])).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yggIj1iqFheC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_generators(batch_size = 32, validation = True):\n",
        "    if validation:\n",
        "      data_gen_args = dict(\n",
        "                       #featurewise_center = True,\n",
        "                       #featurewise_std_normalization = True,\n",
        "                       samplewise_center = True,\n",
        "                       samplewise_std_normalization = True,\n",
        "                       horizontal_flip = True,\n",
        "                       rotation_range=60.,\n",
        "                       validation_split = 0.1)\n",
        "\n",
        "      image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "      \n",
        "      #image_datagen.fit(full_data.x)\n",
        "\n",
        "      train_generator = image_datagen.flow(full_data.x, full_data.y, batch_size=batch_size, subset = 'training')\n",
        "\n",
        "      validation_generator = image_datagen.flow(full_data.x, full_data.y, batch_size=250, subset = 'validation')\n",
        "\n",
        "      return train_generator, validation_generator\n",
        "    \n",
        "    else:\n",
        "      data_gen_args = dict(\n",
        "                       #featurewise_center = True,\n",
        "                       #featurewise_std_normalization = True,\n",
        "                       samplewise_center = True,\n",
        "                       samplewise_std_normalization = True,\n",
        "                       horizontal_flip = True,\n",
        "                       rotation_range=60.)\n",
        "\n",
        "      image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "      \n",
        "      #image_datagen.fit(full_data.x)\n",
        "\n",
        "      train_generator = image_datagen.flow(full_data.x, full_data.y, batch_size=batch_size, subset = 'training')\n",
        "\n",
        "      return train_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5koW02BqZJ9w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model = None\n",
        "\n",
        "# x = base_model.output\n",
        "# part1 = Conv2D(2048, (2, 2), padding = 'same', activation = 'relu')(x)\n",
        "# part1 = MaxPooling2D(pool_size=(2, 2))(part1)\n",
        "# part1 = Dropout(0.15)(part1)\n",
        "\n",
        "# part2 = Conv2D(4096, (2, 2), padding = 'same', activation = 'relu')(part1)\n",
        "# part2 = MaxPooling2D(pool_size=(2, 2))(part2)\n",
        "# part2 = Dropout(0.15)(part2)\n",
        "\n",
        "# part3 = Conv2D(8192, (2, 2), padding = 'same', activation = 'relu')(part2)\n",
        "# part3 = MaxPooling2D(pool_size=(2, 2))(part3)\n",
        "# part3 = Dropout(0.15)(part3)\n",
        "\n",
        "# pooled = GlobalAveragePooling2D()(part3)\n",
        "\n",
        "# # let's add a fully-connected layer with dropout\n",
        "# ending = Dense(1000, activation='relu')(pooled)\n",
        "# ending = Dropout(0.3)(ending)\n",
        "# # and a logistic layer -- let's say we have 200 classes\n",
        "# predictions = Dense(50, activation='softmax')(ending)\n",
        "\n",
        "# # this is the model we will train\n",
        "# model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# # first: train only the top layers (which were randomly initialized)\n",
        "# # i.e. freeze all convolutional InceptionV3 layers\n",
        "\n",
        "# lr_main = 0.0001\n",
        "\n",
        "# #for layer in base_model.layers:\n",
        "# #    layer.trainable = False\n",
        "\n",
        "# # compile the model (should be done *after* setting layers to non-trainable), also set small learning_rate\n",
        "# model.compile(optimizer=Adam(lr = lr_main), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# #model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LgOQN6rJJeLh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install -U --force-reinstall --no-dependencies git+https://github.com/datumbox/keras@bugfix/trainable_bn "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OtyalV_khxg1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b625cae6-26d9-49c2-a942-0db2e700f1ce"
      },
      "cell_type": "code",
      "source": [
        "# create the base pre-trained model\n",
        "base_model = InceptionV3(weights='imagenet', include_top = False)\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "# x = Conv2D(2048, (4, 4), activation = 'relu')(x)\n",
        "# x = BatchNormalization()(x)\n",
        "# x = Conv2D(2048, (3, 3), activation = 'relu')(x)\n",
        "# x = BatchNormalization()(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "# x = Dropout(0.15)(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "#x = Dropout(0.4)(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(50, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "#for layer in base_model.layers:\n",
        "#    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer=Adam(lr = 0.00005), loss='categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ps8Nguj_LvWS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_sizes = [32, 36, 40, 48, 56, 60, 64, 68, 71]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P5bYblcpWTcH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1055
        },
        "outputId": "5c94c01b-eb0d-47d5-c289-40d9b7ad7b40"
      },
      "cell_type": "code",
      "source": [
        "for i, batch_size in enumerate(batch_sizes):\n",
        "    train_generator, validation_generator = make_generators(batch_size = batch_size, validation=1)\n",
        "    \n",
        "    model.fit_generator(train_generator, steps_per_epoch= 2250 / batch_size, epochs=1, verbose = 1, validation_data = validation_generator, validation_steps = 1)\n",
        "    if i > 2:\n",
        "      model.save('drive/main_model' + str(i) + '.h5')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "71/70 [==============================] - 138s 2s/step - loss: 3.1498 - acc: 0.2910 - val_loss: 1.9827 - val_acc: 0.5000\n",
            "Epoch 1/1\n",
            "63/62 [==============================] - 108s 2s/step - loss: 1.4657 - acc: 0.6618 - val_loss: 1.0658 - val_acc: 0.6640\n",
            "Epoch 1/1\n",
            "57/56 [==============================] - 104s 2s/step - loss: 0.8077 - acc: 0.7881 - val_loss: 0.7599 - val_acc: 0.7920\n",
            "Epoch 1/1\n",
            "47/46 [==============================] - 107s 2s/step - loss: 0.5135 - acc: 0.8635 - val_loss: 0.6206 - val_acc: 0.8120\n",
            "Epoch 1/1\n",
            "41/40 [==============================] - 102s 2s/step - loss: 0.3682 - acc: 0.9070 - val_loss: 0.5879 - val_acc: 0.8280\n",
            "Epoch 1/1\n",
            "38/37 [==============================] - 104s 3s/step - loss: 0.2904 - acc: 0.9289 - val_loss: 0.5804 - val_acc: 0.8000\n",
            "Epoch 1/1\n",
            "36/35 [==============================] - 100s 3s/step - loss: 0.2312 - acc: 0.9452 - val_loss: 0.5446 - val_acc: 0.8440\n",
            "Epoch 1/1\n",
            "34/33 [==============================] - 104s 3s/step - loss: 0.2049 - acc: 0.9606 - val_loss: 0.6118 - val_acc: 0.8120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0fc0c1d7876a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2250\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/main_model'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   2589\u001b[0m         \"\"\"\n\u001b[1;32m   2590\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2591\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2593\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mmodel_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minclude_optimizer\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36msave_weights_to_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   2976\u001b[0m                 \u001b[0mparam_dset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2978\u001b[0;31m                 \u001b[0mparam_dset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNLIMITED\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "sDduZo5a1tc8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "85a0e1dc-284b-4ed2-caec-a47e7041cb28"
      },
      "cell_type": "code",
      "source": [
        "for i, batch_size in enumerate(batch_sizes[:-1]):\n",
        "    train_generator = make_generators(batch_size = batch_size, validation=0)    \n",
        "    model.fit_generator(train_generator, steps_per_epoch= 2500 / batch_size, epochs=1, verbose = 1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "79/78 [==============================] - 143s 2s/step - loss: 2.9991 - acc: 0.3042\n",
            "Epoch 1/1\n",
            "70/69 [==============================] - 113s 2s/step - loss: 1.2575 - acc: 0.6999\n",
            "Epoch 1/1\n",
            "63/62 [==============================] - 111s 2s/step - loss: 0.6918 - acc: 0.8234\n",
            "Epoch 1/1\n",
            "53/52 [==============================] - 104s 2s/step - loss: 0.4945 - acc: 0.8571\n",
            "Epoch 1/1\n",
            "45/44 [==============================] - 105s 2s/step - loss: 0.3347 - acc: 0.9104\n",
            "Epoch 1/1\n",
            "42/41 [==============================] - 105s 2s/step - loss: 0.2519 - acc: 0.9486\n",
            "Epoch 1/1\n",
            "40/39 [==============================] - 103s 3s/step - loss: 0.2179 - acc: 0.9424\n",
            "Epoch 1/1\n",
            "37/36 [==============================] - 112s 3s/step - loss: 0.1725 - acc: 0.9595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3cxJfdt8QpAr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('drive/main_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tZwI6JT6BfLo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1873b191-32d3-46b5-f25a-917c5e1ab5fa"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('drive/temp_model.h5')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "jCzec-Ir9F9L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### No validation"
      ]
    },
    {
      "metadata": {
        "id": "lk0gAvitJo3A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model = InceptionV3(weights='imagenet', classes=50, include_top = False)\n",
        "\n",
        "base_model = InceptionV3(weights='imagenet', include_top = False)\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalMaxPooling2D()(x)\n",
        "\n",
        "# let's add a fully-connected layer with dropout\n",
        "x = Dense(1000, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(50, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable), also set small learning_rate\n",
        "model.compile(optimizer=Adam(lr=0.00004), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m-ZtADbF9mXL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "batches_per_training = 10\n",
        "\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mErm3AP59ZBs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_gen_args = dict(#rescale=1./256,\n",
        "                     samplewise_center = True,\n",
        "                     samplewise_std_normalization = True,\n",
        "                     horizontal_flip = True,\n",
        "                     rotation_range=90.)\n",
        "\n",
        "def make_generator(batch_size = 32, data_gen_args = data_gen_args, path = path, batches_per_training = 10):\n",
        "  \n",
        "  image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "  train_generator = image_datagen.flow_from_directory(path, target_size=(299, 299), batch_size=batches_per_training*batch_size)\n",
        "  \n",
        "  return train_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c_E5IM8I0nj4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_sizes = [32, 36, 40, 47, 54, 60, 66, 71]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zRtRobFWWBXV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_sizes = [69, 71]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sho04EYD9I3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1913
        },
        "outputId": "b2c579c9-8695-44c5-aa16-0f2b87602fbc"
      },
      "cell_type": "code",
      "source": [
        "for batch_size in batch_sizes:\n",
        "    print('train on batch size:', batch_size)\n",
        "    train_generator = make_generator(batch_size = batch_size)\n",
        "    batches = 0\n",
        "    for x_batch, y_batch in train_generator:\n",
        "        model.fit(x_batch, y_batch,\n",
        "          batch_size=batch_size, epochs=1, shuffle=False)\n",
        "        batches += batches_per_training\n",
        "\n",
        "        if (batches * batch_size) >= 2500:\n",
        "            break"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train on batch size: 32\n",
            "Found 2500 images belonging to 50 classes.\n",
            "Epoch 1/1\n",
            "320/320 [==============================] - 33s 102ms/step - loss: 6.5379 - acc: 0.0219\n",
            "Epoch 1/1\n",
            "320/320 [==============================] - 13s 40ms/step - loss: 5.3813 - acc: 0.0500\n",
            "Epoch 1/1\n",
            "320/320 [==============================] - 13s 40ms/step - loss: 4.8115 - acc: 0.0625\n",
            "Epoch 1/1\n",
            "320/320 [==============================] - 13s 40ms/step - loss: 4.2825 - acc: 0.0938\n",
            "Epoch 1/1\n",
            "320/320 [==============================] - 13s 40ms/step - loss: 4.0895 - acc: 0.0687\n",
            "Epoch 1/1\n",
            "320/320 [==============================] - 13s 40ms/step - loss: 3.9113 - acc: 0.1125\n",
            "Epoch 1/1\n",
            "320/320 [==============================] - 13s 40ms/step - loss: 3.5866 - acc: 0.1562\n",
            "Epoch 1/1\n",
            "260/260 [==============================] - 13s 48ms/step - loss: 3.3307 - acc: 0.1923\n",
            "train on batch size: 36\n",
            "Found 2500 images belonging to 50 classes.\n",
            "Epoch 1/1\n",
            "360/360 [==============================] - 15s 41ms/step - loss: 2.8978 - acc: 0.2833\n",
            "Epoch 1/1\n",
            "360/360 [==============================] - 15s 41ms/step - loss: 2.6947 - acc: 0.3028\n",
            "Epoch 1/1\n",
            "360/360 [==============================] - 15s 41ms/step - loss: 2.3727 - acc: 0.3611\n",
            "Epoch 1/1\n",
            "360/360 [==============================] - 15s 42ms/step - loss: 2.3538 - acc: 0.3361\n",
            "Epoch 1/1\n",
            "108/360 [========>.....................] - ETA: 10s - loss: 2.3228 - acc: 0.4167"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "360/360 [==============================] - 15s 41ms/step - loss: 2.1406 - acc: 0.4167\n",
            "Epoch 1/1\n",
            "360/360 [==============================] - 15s 41ms/step - loss: 2.1323 - acc: 0.3917\n",
            "Epoch 1/1\n",
            "340/340 [==============================] - 17s 49ms/step - loss: 2.1076 - acc: 0.3882\n",
            "train on batch size: 40\n",
            "Found 2500 images belonging to 50 classes.\n",
            "Epoch 1/1\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 1.5783 - acc: 0.5450\n",
            "Epoch 1/1\n",
            "400/400 [==============================] - 16s 41ms/step - loss: 1.6166 - acc: 0.5400\n",
            "Epoch 1/1\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 1.5043 - acc: 0.5350\n",
            "Epoch 1/1\n",
            "400/400 [==============================] - 16s 41ms/step - loss: 1.6264 - acc: 0.5325\n",
            "Epoch 1/1\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 1.5440 - acc: 0.5250\n",
            "Epoch 1/1\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 1.4594 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 7s 65ms/step - loss: 1.4605 - acc: 0.5600\n",
            "train on batch size: 47\n",
            "Found 2500 images belonging to 50 classes.\n",
            "Epoch 1/1\n",
            "470/470 [==============================] - 24s 52ms/step - loss: 1.2305 - acc: 0.6298\n",
            "Epoch 1/1\n",
            "470/470 [==============================] - 18s 38ms/step - loss: 1.2329 - acc: 0.6426\n",
            "Epoch 1/1\n",
            "470/470 [==============================] - 18s 38ms/step - loss: 1.1599 - acc: 0.6596\n",
            "Epoch 1/1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "470/470 [==============================] - 18s 38ms/step - loss: 1.1069 - acc: 0.6596\n",
            "Epoch 1/1\n",
            "470/470 [==============================] - 18s 38ms/step - loss: 1.1997 - acc: 0.6319\n",
            "Epoch 1/1\n",
            "150/150 [==============================] - 8s 53ms/step - loss: 1.3956 - acc: 0.6067\n",
            "train on batch size: 54\n",
            "Found 2500 images belonging to 50 classes.\n",
            "Epoch 1/1\n",
            "540/540 [==============================] - 28s 52ms/step - loss: 1.0342 - acc: 0.6611\n",
            "Epoch 1/1\n",
            "540/540 [==============================] - 20s 38ms/step - loss: 0.9664 - acc: 0.7148\n",
            "Epoch 1/1\n",
            "540/540 [==============================] - 20s 38ms/step - loss: 0.8556 - acc: 0.7426\n",
            "Epoch 1/1\n",
            "540/540 [==============================] - 20s 38ms/step - loss: 0.9245 - acc: 0.7037\n",
            "Epoch 1/1\n",
            "340/340 [==============================] - 13s 38ms/step - loss: 1.0979 - acc: 0.6676\n",
            "train on batch size: 60\n",
            "Found 2500 images belonging to 50 classes.\n",
            "Epoch 1/1\n",
            "600/600 [==============================] - 30s 50ms/step - loss: 0.8027 - acc: 0.7533\n",
            "Epoch 1/1\n",
            "600/600 [==============================] - 22s 37ms/step - loss: 0.7441 - acc: 0.7817\n",
            "Epoch 1/1\n",
            "600/600 [==============================] - 22s 37ms/step - loss: 0.8356 - acc: 0.7417\n",
            "Epoch 1/1\n",
            "600/600 [==============================] - 22s 37ms/step - loss: 0.8157 - acc: 0.7533\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.7151 - acc: 0.7900\n",
            "train on batch size: 66\n",
            "Found 2500 images belonging to 50 classes.\n",
            "Epoch 1/1\n",
            "198/660 [========>.....................] - ETA: 36s - loss: 0.7565 - acc: 0.7727"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "660/660 [==============================] - 33s 50ms/step - loss: 0.7768 - acc: 0.7682\n",
            "Epoch 1/1\n",
            "660/660 [==============================] - 25s 37ms/step - loss: 0.6633 - acc: 0.7985\n",
            "Epoch 1/1\n",
            "660/660 [==============================] - 25s 37ms/step - loss: 0.6851 - acc: 0.7682\n",
            "Epoch 1/1\n",
            "520/520 [==============================] - 19s 37ms/step - loss: 0.6760 - acc: 0.7692\n",
            "train on batch size: 71\n",
            "Found 2500 images belonging to 50 classes.\n",
            "Epoch 1/1\n",
            "710/710 [==============================] - 35s 49ms/step - loss: 0.6347 - acc: 0.8085\n",
            "Epoch 1/1\n",
            "710/710 [==============================] - 26s 37ms/step - loss: 0.5575 - acc: 0.8127\n",
            "Epoch 1/1\n",
            "710/710 [==============================] - 26s 37ms/step - loss: 0.6569 - acc: 0.8014\n",
            "Epoch 1/1\n",
            "370/370 [==============================] - 16s 44ms/step - loss: 0.6053 - acc: 0.8216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8LerxaQx05L-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('drive/birds_model.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LmUFscvNVvq2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = load_model('drive/birds_model.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}